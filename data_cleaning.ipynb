{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17764d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: duckdb in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\Sivapriya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\Sivapriya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\Sivapriya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e12fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import duckdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e555c25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final sampled rows: 35000\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "file_path = r\"P:\\IIM Ranchi\\nasdaq_exteral_data.csv\"\n",
    "\n",
    "duckdb_conn = duckdb.connect()\n",
    "\n",
    "query = f\"\"\"\n",
    "WITH data AS (\n",
    "    SELECT\n",
    "        *\n",
    "    FROM read_csv(\n",
    "        '{file_path}',\n",
    "        AUTO_DETECT=TRUE,\n",
    "        DELIM=',',\n",
    "        QUOTE='\"',\n",
    "        ESCAPE='\\\"',          -- handles messy quotes\n",
    "        IGNORE_ERRORS=TRUE,   -- skip broken rows\n",
    "        SAMPLE_SIZE=200000    -- improves schema detection\n",
    "    )\n",
    "    WHERE\n",
    "        Article IS NOT NULL\n",
    "        AND TRIM(Article) <> ''\n",
    "        AND Date IS NOT NULL\n",
    "        AND TRIM(Stock_symbol) <> ''\n",
    ")\n",
    "SELECT *\n",
    "FROM data\n",
    "USING SAMPLE reservoir(35000);\n",
    "\"\"\"\n",
    "\n",
    "sampled_df = duckdb_conn.execute(query).df()\n",
    "sampled_df.to_parquet(\"sampled_35k_news.parquet\")\n",
    "\n",
    "print(\"Final sampled rows:\", len(sampled_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "298b03a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"sampled_35k_news.parquet\")\n",
    "\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56e9d276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date Stock_symbol                                            Article\n",
      "0 2022-11-04            A  Microchip Technology MCHP reported second-quar...\n",
      "1 2023-01-19            A  Momentum investing is all about the idea of fo...\n",
      "2 2023-02-23            A  Etsy, Inc. ETSY reported fourth-quarter 2022 e...\n",
      "3 2023-08-16            A  What you need to know…\\nThe S&P 500 Index ($SP...\n",
      "4 2023-08-25            A  By David Carnevali\\nNEW YORK, Aug 25 (Reuters)...\n",
      "Cleaned size: 35000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"sampled_35k_news.parquet\")\n",
    "\n",
    "# Keep essential columns — adjust names as needed\n",
    "expected_cols = [\"Date\", \"Stock_symbol\", \"Article\"]\n",
    "df = df[[c for c in expected_cols if c in df.columns]]\n",
    "\n",
    "# Clean missing/empty articles\n",
    "df = df.dropna(subset=['Article'])\n",
    "df = df[df['Article'].str.strip() != \"\"]\n",
    "\n",
    "# Parse dates\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort for consistency\n",
    "df = df.sort_values([\"Stock_symbol\", \"Date\"]).reset_index(drop=True)\n",
    "\n",
    "df.to_parquet(\"sampled_35k_clean.parquet\")\n",
    "print(df.head())\n",
    "print(\"Cleaned size:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13a04f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras 3.9.2\n",
      "Uninstalling keras-3.9.2:\n",
      "  Successfully uninstalled keras-3.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall keras -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04247a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\Sivapriya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.15 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for tensorflow==2.15\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4a13ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow<2.21,>=2.20 (from tf-keras)\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (24.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading protobuf-6.33.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (74.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.73.0)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.13.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.7)\n",
      "Requirement already satisfied: pillow in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (10.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sivapriya\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sivapriya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.8/1.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "   ---------------------------------------- 0.0/331.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/331.9 MB 6.7 MB/s eta 0:00:50\n",
      "   ---------------------------------------- 3.1/331.9 MB 7.7 MB/s eta 0:00:43\n",
      "    --------------------------------------- 5.5/331.9 MB 9.1 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 8.4/331.9 MB 10.6 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 11.5/331.9 MB 11.6 MB/s eta 0:00:28\n",
      "   - -------------------------------------- 15.7/331.9 MB 13.0 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 20.4/331.9 MB 14.3 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 25.4/331.9 MB 15.6 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 32.2/331.9 MB 17.5 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 39.3/331.9 MB 19.1 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 46.9/331.9 MB 20.7 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 52.7/331.9 MB 21.4 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 59.8/331.9 MB 22.3 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 67.1/331.9 MB 23.3 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 75.2/331.9 MB 24.2 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 82.6/331.9 MB 25.0 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 89.9/331.9 MB 25.5 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 97.8/331.9 MB 26.1 MB/s eta 0:00:09\n",
      "   ------------ -------------------------- 104.1/331.9 MB 26.4 MB/s eta 0:00:09\n",
      "   ------------- ------------------------- 111.9/331.9 MB 27.0 MB/s eta 0:00:09\n",
      "   ------------- ------------------------- 119.0/331.9 MB 27.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------ 126.1/331.9 MB 27.6 MB/s eta 0:00:08\n",
      "   --------------- ----------------------- 132.9/331.9 MB 27.7 MB/s eta 0:00:08\n",
      "   ---------------- ---------------------- 140.0/331.9 MB 27.9 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 147.8/331.9 MB 28.3 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 155.5/331.9 MB 28.6 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 163.6/331.9 MB 29.0 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 170.1/331.9 MB 29.1 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 178.0/331.9 MB 29.5 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 183.8/331.9 MB 29.4 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 184.8/331.9 MB 28.6 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 187.2/331.9 MB 28.1 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 187.4/331.9 MB 27.6 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 192.7/331.9 MB 27.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 198.7/331.9 MB 27.3 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 204.2/331.9 MB 27.2 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 209.7/331.9 MB 27.2 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 216.5/331.9 MB 27.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 223.1/331.9 MB 27.5 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 230.2/331.9 MB 27.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 237.8/331.9 MB 27.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 245.4/331.9 MB 28.0 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 252.4/331.9 MB 28.1 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 261.4/331.9 MB 28.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 269.5/331.9 MB 30.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 276.3/331.9 MB 30.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 283.6/331.9 MB 31.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 290.5/331.9 MB 31.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 298.6/331.9 MB 31.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 306.2/331.9 MB 31.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 315.4/331.9 MB 32.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 322.7/331.9 MB 32.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  330.6/331.9 MB 32.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 331.9/331.9 MB 25.6 MB/s eta 0:00:00\n",
      "Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 12.9 MB/s eta 0:00:00\n",
      "Downloading protobuf-6.33.2-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 25.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 19.8 MB/s eta 0:00:00\n",
      "Installing collected packages: protobuf, tensorboard, keras, tensorflow, tf-keras\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.8\n",
      "    Uninstalling protobuf-4.25.8:\n",
      "      Successfully uninstalled protobuf-4.25.8\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.19.0\n",
      "    Uninstalling tensorboard-2.19.0:\n",
      "      Successfully uninstalled tensorboard-2.19.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.19.0\n",
      "    Uninstalling tensorflow-2.19.0:\n",
      "      Successfully uninstalled tensorflow-2.19.0\n",
      "Successfully installed keras-3.12.0 protobuf-6.33.2 tensorboard-2.20.0 tensorflow-2.20.0 tf-keras-2.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\Sivapriya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\Sivapriya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "  WARNING: The script tensorboard.exe is installed in 'c:\\Users\\Sivapriya\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe and toco.exe are installed in 'c:\\Users\\Sivapriya\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\Sivapriya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "flwr 1.15.2 requires protobuf<5.0.0,>=4.21.6, but you have protobuf 6.33.2 which is incompatible.\n",
      "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.2 which is incompatible.\n",
      "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.2 which is incompatible.\n",
      "mediapipe 0.10.14 requires protobuf<5,>=4.25.3, but you have protobuf 6.33.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6d8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sivapriya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Sivapriya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [42:21<00:00,  6.96s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done embedding!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "df = pd.read_parquet(\"sampled_35k_clean.parquet\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load model on GPU\n",
    "model = SentenceTransformer(\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "def embed_batch(texts, batch_size=96):  \n",
    "    all_embs = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        emb = model.encode(\n",
    "            batch,\n",
    "            batch_size=batch_size,\n",
    "            device=device,\n",
    "            show_progress_bar=False\n",
    "        )\n",
    "        all_embs.append(emb)\n",
    "    return np.vstack(all_embs)\n",
    "\n",
    "df[\"embedding\"] = list(embed_batch(df[\"Article\"].tolist()))\n",
    "df.to_parquet(\"sampled_35k_embedded.parquet\")\n",
    "\n",
    "print(\"Done embedding!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6957b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Current device:\", torch.cuda.current_device() if torch.cuda.is_available() else \"None\")\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23bfbfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved daily embeddings!\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"sampled_35k_embedded.parquet\")\n",
    "\n",
    "daily_embeddings = (\n",
    "    df.groupby([\"Stock_symbol\", \"Date\"])[\"embedding\"]\n",
    "      .apply(lambda x: np.mean(np.vstack(x), axis=0))\n",
    "      .reset_index()\n",
    "      .rename(columns={\"embedding\": \"E_t\"})\n",
    ")\n",
    "\n",
    "daily_embeddings.to_parquet(\"daily_embeddings.parquet\")\n",
    "print(\"Saved daily embeddings!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7842117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMA baseline computed correctly (no look-ahead).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "alpha = 0.2\n",
    "\n",
    "daily_embeddings = pd.read_parquet(\"daily_embeddings.parquet\")\n",
    "\n",
    "def compute_ema(arr, alpha):\n",
    "    ema = arr[0]\n",
    "    out = [ema]\n",
    "\n",
    "    for v in arr[1:]:\n",
    "        ema = alpha * v + (1 - alpha) * ema\n",
    "        out.append(ema)\n",
    "\n",
    "    return np.vstack(out)\n",
    "\n",
    "records = []\n",
    "\n",
    "for stock, g in daily_embeddings.groupby(\"Stock_symbol\"):\n",
    "    g = g.sort_values(\"Date\")\n",
    "\n",
    "    # THIS was missing\n",
    "    E_arr = np.vstack(g[\"E_t\"].values)\n",
    "\n",
    "    mu_arr = compute_ema(E_arr, alpha)\n",
    "\n",
    "    # shift to ensure mu_{t-1}\n",
    "    mu_arr = np.vstack([mu_arr[0], mu_arr[:-1]])\n",
    "\n",
    "    g[\"mu_t_minus_1\"] = list(mu_arr)\n",
    "    records.append(g)\n",
    "\n",
    "ssd_base = pd.concat(records, ignore_index=True)\n",
    "ssd_base.to_parquet(\"ssd_baseline.parquet\")\n",
    "\n",
    "print(\"EMA baseline computed correctly (no look-ahead).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7db7277d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSD computed!\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "def cosine_distance(a, b):\n",
    "    return 1 - (np.dot(a, b) / (norm(a) * norm(b)))\n",
    "\n",
    "ssd_base[\"SSD\"] = [\n",
    "    cosine_distance(e, mu)\n",
    "    for e, mu in zip(ssd_base[\"E_t\"], ssd_base[\"mu_t_minus_1\"])\n",
    "]\n",
    "\n",
    "ssd_base.to_parquet(\"ssd_final.parquet\")\n",
    "print(\"SSD computed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
